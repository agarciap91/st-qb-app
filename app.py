import streamlit as st
import boto3
import json
from botocore.exceptions import ClientError, NoCredentialsError
import time
from gtts import gTTS
import io
import base64
import speech_recognition as sr
from audio_recorder_streamlit import audio_recorder
import tempfile
import os

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Chat con AWS Bedrock - Con Voz",
    page_icon="ü§ñ",
    layout="wide"
)

# Funci√≥n para verificar credenciales AWS
def verify_aws_credentials(region_name, aws_access_key_id=None, aws_secret_access_key=None):
    try:
        if aws_access_key_id and aws_secret_access_key:
            sts_client = boto3.client(
                'sts',
                region_name=region_name,
                aws_access_key_id=aws_access_key_id,
                aws_secret_access_key=aws_secret_access_key
            )
        else:
            sts_client = boto3.client('sts', region_name=region_name)
        
        # Verificar identidad
        response = sts_client.get_caller_identity()
        return True, response.get('Arn', 'Unknown')
    except Exception as e:
        return False, str(e)

# Funci√≥n para inicializar el cliente de Bedrock
@st.cache_resource
def init_bedrock_client(region_name):
    try:
        # Usar credenciales desde secrets.toml
        access_key = st.secrets["AWS_ACCESS_KEY_ID"]
        secret_key = st.secrets["AWS_SECRET_ACCESS_KEY"]
        
        # Verificar credenciales
        valid, info = verify_aws_credentials(region_name, access_key, secret_key)
        if not valid:
            st.error(f"Credenciales inv√°lidas: {info}")
            return None
        
        bedrock = boto3.client(
            'bedrock-runtime',
            region_name=region_name,
            aws_access_key_id=access_key,
            aws_secret_access_key=secret_key
        )
        
        return bedrock
    except KeyError as e:
        st.error(f"Error: Falta la clave en secrets.toml: {str(e)}")
        return None
    except ClientError as e:
        st.error(f"Error de cliente AWS: {str(e)}")
        return None
    except Exception as e:
        st.error(f"Error al inicializar cliente Bedrock: {str(e)}")
        return None

# Funci√≥n para convertir texto a voz
def text_to_speech(text, lang='es'):
    try:
        # Limitar el texto para evitar archivos muy grandes
        if len(text) > 1000:
            text = text[:1000] + "..."
        
        # Crear el objeto gTTS
        tts = gTTS(text=text, lang=lang, slow=False)
        
        # Guardar en un buffer de memoria
        audio_buffer = io.BytesIO()
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)
        
        return audio_buffer.getvalue()
    except Exception as e:
        st.error(f"Error al generar audio: {str(e)}")
        return None

# Funci√≥n para convertir voz a texto
def speech_to_text(audio_data, language='es-ES'):
    try:
        # Crear un archivo temporal para el audio
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            tmp_file.write(audio_data)
            tmp_file_path = tmp_file.name
        
        # Inicializar el reconocedor
        recognizer = sr.Recognizer()
        
        # Cargar el archivo de audio
        with sr.AudioFile(tmp_file_path) as source:
            # Ajustar para ruido ambiente
            recognizer.adjust_for_ambient_noise(source)
            # Grabar el audio
            audio = recognizer.record(source)
        
        # Convertir a texto usando Google Speech Recognition
        text = recognizer.recognize_google(audio, language=language)
        
        # Limpiar el archivo temporal
        os.unlink(tmp_file_path)
        
        return text
    
    except sr.UnknownValueError:
        return "No se pudo entender el audio. Intenta hablar m√°s claro."
    except sr.RequestError as e:
        return f"Error del servicio de reconocimiento: {str(e)}"
    except Exception as e:
        return f"Error al procesar el audio: {str(e)}"
    finally:
        # Asegurar que el archivo temporal se elimine
        if 'tmp_file_path' in locals() and os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)

# Funci√≥n para invocar el modelo
def invoke_bedrock_model(bedrock_client, model_id, prompt, max_tokens=1000, temperature=0.7):
    try:
        # Configuraci√≥n del cuerpo de la solicitud seg√∫n el modelo
        if "anthropic" in model_id.lower():
            body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": max_tokens,
                "temperature": temperature,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }
        elif "ai21" in model_id.lower():
            body = {
                "prompt": prompt,
                "maxTokens": max_tokens,
                "temperature": temperature
            }
        elif "amazon" in model_id.lower():
            body = {
                "inputText": prompt,
                "textGenerationConfig": {
                    "maxTokenCount": max_tokens,
                    "temperature": temperature
                }
            }
        elif "cohere" in model_id.lower():
            body = {
                "prompt": prompt,
                "max_tokens": max_tokens,
                "temperature": temperature
            }
        else:
            # Configuraci√≥n gen√©rica
            body = {
                "prompt": prompt,
                "max_tokens": max_tokens,
                "temperature": temperature
            }

        # Invocar el modelo
        response = bedrock_client.invoke_model(
            modelId=model_id,
            body=json.dumps(body),
            contentType='application/json',
            accept='application/json'
        )

        # Procesar la respuesta
        response_body = json.loads(response['body'].read())
        
        # Extraer el texto seg√∫n el modelo
        if "anthropic" in model_id.lower():
            return response_body.get('content', [{}])[0].get('text', '')
        elif "ai21" in model_id.lower():
            return response_body.get('completions', [{}])[0].get('data', {}).get('text', '')
        elif "amazon" in model_id.lower():
            return response_body.get('results', [{}])[0].get('outputText', '')
        elif "cohere" in model_id.lower():
            return response_body.get('generations', [{}])[0].get('text', '')
        else:
            return str(response_body)

    except ClientError as e:
        error_code = e.response['Error']['Code']
        error_message = e.response['Error']['Message']
        st.error(f"Error de AWS: {error_code} - {error_message}")
        return None
    except Exception as e:
        st.error(f"Error al invocar el modelo: {str(e)}")
        return None

# Interfaz principal
def main():
    st.title("ü§ñ Chat con AWS Bedrock - Con Voz")
    st.markdown("Chatea con modelos de IA usando AWS Bedrock y escucha las respuestas")

    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        # Control de voz
        voice_enabled = st.checkbox("üîä Activar respuestas de voz", value=True)
        speech_input_enabled = st.checkbox("üé§ Activar entrada por voz", value=True)
        
        if voice_enabled:
            voice_lang = st.selectbox(
                "Idioma de voz:",
                options=[
                    ("es", "Espa√±ol"),
                    ("en", "English"),
                    ("fr", "Fran√ßais"),
                    ("de", "Deutsch"),
                    ("it", "Italiano"),
                    ("pt", "Portugu√™s")
                ],
                format_func=lambda x: x[1]
            )[0]
        
        if speech_input_enabled:
            speech_lang = st.selectbox(
                "Idioma de reconocimiento:",
                options=[
                    ("es-ES", "Espa√±ol"),
                    ("en-US", "English (US)"),
                    ("en-GB", "English (UK)"),
                    ("fr-FR", "Fran√ßais"),
                    ("de-DE", "Deutsch"),
                    ("it-IT", "Italiano"),
                    ("pt-BR", "Portugu√™s (Brasil)")
                ],
                format_func=lambda x: x[1]
            )[0]
        
        st.divider()
        
        # Bot√≥n para limpiar chat
        if st.button("üóëÔ∏è Limpiar Chat"):
            st.session_state.messages = []
            st.rerun()

    # Configuraci√≥n por defecto
    aws_region = "us-east-1"
    selected_model = "anthropic.claude-3-sonnet-20240229-v1:0"  # Claude 3 Sonnet
    max_tokens = 1000
    temperature = 0.7
    use_secrets = True

    # Inicializar el cliente de Bedrock
    bedrock_client = init_bedrock_client(aws_region)
    
    if not bedrock_client:
        st.error("Error de conexi√≥n con AWS Bedrock. Verifica tu configuraci√≥n.")
        return

    # Inicializar el historial de mensajes
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Mostrar el historial de mensajes
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Si es un mensaje del asistente y tiene audio, mostrarlo
            if message["role"] == "assistant" and "audio" in message:
                st.audio(message["audio"], format="audio/mp3")

    # Secci√≥n de entrada por voz
    if speech_input_enabled:
        st.markdown("### üé§ Graba tu pregunta")
        
        # Grabador de audio
        audio_bytes = audio_recorder(
            text="Presiona para grabar",
            recording_color="#e74c3c",
            neutral_color="#34495e",
            icon_name="microphone",
            icon_size="2x",
        )
        
        # Procesar audio grabado
        if audio_bytes:
            st.audio(audio_bytes, format="audio/wav")
            
            # Convertir audio a texto
            with st.spinner("Procesando audio..."):
                transcribed_text = speech_to_text(audio_bytes, speech_lang)
                
                if transcribed_text and not transcribed_text.startswith("No se pudo") and not transcribed_text.startswith("Error"):
                    st.success(f"üéØ Texto reconocido: *{transcribed_text}*")
                    
                    # Procesar como si fuera un mensaje de texto
                    process_user_message(transcribed_text, bedrock_client, selected_model, max_tokens, temperature, voice_enabled, voice_lang if voice_enabled else None)
                    st.rerun()
                else:
                    st.error(transcribed_text)
        
        st.divider()

    # Input del usuario por texto
    if prompt := st.chat_input("Escribe tu mensaje aqu√≠..."):
        process_user_message(prompt, bedrock_client, selected_model, max_tokens, temperature, voice_enabled, voice_lang if voice_enabled else None)
        st.rerun()

# Funci√≥n auxiliar para procesar mensajes del usuario
def process_user_message(prompt, bedrock_client, selected_model, max_tokens, temperature, voice_enabled, voice_lang):
    # Agregar mensaje del usuario al historial
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Mostrar mensaje del usuario
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generar respuesta del asistente
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            response = invoke_bedrock_model(
                bedrock_client, 
                selected_model, 
                prompt, 
                max_tokens, 
                temperature
            )
            
            if response:
                st.markdown(response)
                
                # Preparar el mensaje para agregar al historial
                message_data = {"role": "assistant", "content": response}
                
                # Generar audio si est√° habilitado
                if voice_enabled and voice_lang:
                    with st.spinner("Generando audio..."):
                        audio_data = text_to_speech(response, voice_lang)
                        
                        if audio_data:
                            # Mostrar el audio
                            st.audio(audio_data, format="audio/mp3")
                            # Agregar audio al mensaje
                            message_data["audio"] = audio_data
                        else:
                            st.warning("No se pudo generar el audio")
                
                # Agregar respuesta al historial
                st.session_state.messages.append(message_data)
            else:
                st.error("No se pudo generar una respuesta. Verifica la configuraci√≥n.")

if __name__ == "__main__":
    main()
